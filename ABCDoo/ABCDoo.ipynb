{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41c323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import adjusted_mutual_info_score as AMI\n",
    "import partition_igraph\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sparse \n",
    "import time\n",
    "from statistics import mode\n",
    "from abcd_graph import ABCDGraph, ABCDParams\n",
    "import csv\n",
    "import subprocess\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from CAS import *\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae3fdf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this assumes community 0 are outliers and 'gt' exists in graph G\n",
    "## M: membership matrix\n",
    "## S: score matrix (C or Beta)\n",
    "def outliers_AUC(G, M, S):\n",
    "    y = [int(x>0) for x in G.vs['gt']]\n",
    "    x = np.array(S.max(axis=1).todense()).flatten()\n",
    "    ctr = Counter(np.array(M.sum(axis=1)).flatten())\n",
    "    print('With matrix M:\\noutliers:',ctr[0])\n",
    "    print('correct outliers:',sum((np.array(M.sum(axis=1)).flatten() == 0) & (np.array(G.vs['gt']) == 0)))\n",
    "    print('\\nWith scores:\\noutlier AUC:',AUC(y,x)) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2d8af6",
   "metadata": {},
   "source": [
    "## ABCD-oo graphs\n",
    "\n",
    "Main 2 files:\n",
    "\n",
    "```\n",
    "networkfile<xi>_<eta>_<rep>.txt : the edges, 1-based node ids, tab separated\n",
    "communityfile<xi>_<eta>_<rep>.txt : node <tab> list of communities in [], for example:\n",
    "1       [24]\n",
    "2       [3, 28]\n",
    "3       [10]\n",
    "```\n",
    "\n",
    "All files for one case:\n",
    "\n",
    "```\n",
    "communityfile0.5_1.5_10.txt\n",
    "communitysizesfile0.5_1.5_10.txt\n",
    "degreefile0.5_1.5_10.txt\n",
    "networkfile0.5_1.5_10.txt\n",
    "```\n",
    "\n",
    "All graph have 250 outlier nodes, mapped to community 0 below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4806df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/ABCDoo/'\n",
    "#path = '../Datasets/ABCDoo/'\n",
    "def readGraph(xi=0.5, eta=1.5, rep=1):\n",
    "    ## read edges, build graph\n",
    "    fn = path+'networkfile'+str(xi)+'_'+str(eta)+'_'+str(rep)+'.txt'\n",
    "    Edges = pd.read_csv(fn, sep='\\t', header=None)-1\n",
    "    G = ig.Graph.DataFrame(Edges, directed=False)\n",
    "    ## read communities\n",
    "    fn = path+'communityfile'+str(xi)+'_'+str(eta)+'_'+str(rep)+'.txt'\n",
    "    L = []\n",
    "    with open(fn, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            x = line.split('\\t')\n",
    "            L.append([int(y)-1 for y in x[1].rstrip()[1:-1].split(',')]) ## map to 0-based\n",
    "    G.vs['comms'] = L\n",
    "    G.vs['n_comms'] = [len(x) for x in G.vs['comms']]\n",
    "    return G\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743141a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oNMI = '/Users/francois/Book/GraphMiningNotebooks/oNMI/onmi'          ## overlapping NMI executable\n",
    "oNMI = '/work/home/fcthebe/Tools/oNMI/onmi'          ## overlapping NMI executable\n",
    "\n",
    "## input format: \n",
    "def compute_oNMI(First, Second):\n",
    "    fn1 = '__'+str(random.random())[2:]\n",
    "    with open(fn1,\"w\") as f:\n",
    "        wr = csv.writer(f, delimiter=\" \")\n",
    "        wr.writerows(First)\n",
    "    f.close()   \n",
    "\n",
    "    fn2 = '__'+str(random.random())[2:]\n",
    "    with open(fn2,\"w\") as f:\n",
    "        wr = csv.writer(f, delimiter=\" \")\n",
    "        wr.writerows(Second)\n",
    "    f.close()   \n",
    "    x = float(subprocess.check_output([oNMI,fn1,fn2]).decode(\"utf-8\").split()[1])\n",
    "    _ = os.system('rm '+fn1)\n",
    "    _ = os.system('rm '+fn2)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a211b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memberships2list(S):\n",
    "    L = []\n",
    "    for i in range(len(S.indptr)-1):\n",
    "        if S.indptr[i] == S.indptr[i+1]:\n",
    "            L.append([0]) ## no membership == outlier (community 0)\n",
    "        else:\n",
    "            L.append(list(S.indices[S.indptr[i]:S.indptr[i+1]]+1)) ## 1-based\n",
    "    return L\n",
    "\n",
    "## given list of node memberships, return list of communities\n",
    "def mems2comms(X):\n",
    "    nc = max(set([i for j in X for i in j]))+1  \n",
    "    n = len(X)\n",
    "    L = [[] for _ in range(nc)]\n",
    "    for i in range(n):\n",
    "        for j in X[i]:\n",
    "            L[j].append(i)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "147106c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CPM(g, k=3):\n",
    "    cls = list(map(set, g.cliques(min=k,max=k)))\n",
    "    edgelist = []\n",
    "    for i in range(len(cls)):\n",
    "        edgelist.append((i,i))\n",
    "    for i,j in combinations(range(len(cls)),2):\n",
    "        if len(cls[i].intersection(cls[j])) >= (k-1):\n",
    "            edgelist.append((i,j))\n",
    "    cg = ig.Graph(edgelist, directed=False)\n",
    "    clusters = cg.connected_components()\n",
    "    L = []\n",
    "    for cluster in clusters:\n",
    "        members = set()\n",
    "        for i in cluster:\n",
    "            members.update(cls[i])\n",
    "        L.append(set(g.vs[members][\"name\"]))\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b7d882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EgoSplit(G, split='CC', algo='LP'):\n",
    "    g = G.copy()\n",
    "    ## implement ego-split approach with LP+LP and LP+ECG\n",
    "    g.vs['original'] = g.vs['name']\n",
    "    ## use the vertex names to avoid issues when vertices are re-mapped ...\n",
    "    names = g.vs['name']\n",
    "    ## step 1 - ego-net splits\n",
    "    for nm in names:\n",
    "        v = g.vs.find(nm).index\n",
    "        n = g.neighbors(v)\n",
    "        sg = g.subgraph(n)\n",
    "        if split == 'LP':\n",
    "            x = sg.community_label_propagation().membership\n",
    "        else:\n",
    "            x = sg.connected_components().membership\n",
    "        if np.min(x)==-1:\n",
    "            x = [i+1 for i in x]\n",
    "        for j in set(x):\n",
    "            g.add_vertex(name=nm+'.'+str(j),original=nm)\n",
    "\n",
    "        l = sg.vs['name']\n",
    "        for j in range(len(x)):\n",
    "            g.add_edge(nm+'.'+str(x[j]) , l[j])\n",
    "        g.delete_vertices(v)\n",
    "    ## step 2 -- cluster w.r.t. multiple personae\n",
    "    if algo=='LP':\n",
    "        cl = g.community_label_propagation()\n",
    "    else:\n",
    "        cl = g.community_ecg(ens_size=32, final='leiden') ## Leiden\n",
    "    C = [set(sg.vs['original']) for sg in cl.subgraphs()]\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc839d6c",
   "metadata": {},
   "source": [
    "# Testing ego-split\n",
    "\n",
    "Also tried CPM, no use\n",
    "\n",
    "We use a variation of the ego-split clustering method proposed in [Epasto] and presented in [Book], where we use ensemble clustering after splitting node into multiple copies depending on their respective neighbourhoods.\n",
    "Since eg-splitting tends to produce many very small communities, we set a minimum size of 10 for the communities.\n",
    "We compare the resulting ES communities with the GT, followed by one round of applying the NIEF CAS score to update the communities w.r.t. a range of threshold values. \n",
    "\n",
    "In practical applications, since the GT is unknown, it is not always clear how to pick a good threshold when using CAS scores.\n",
    "We present some possible methods by computing respectively the average number of communities (for non-outlier nodes) and the number of outlier nodes for several choices of threshold values.\n",
    "\n",
    "\n",
    "NIEF: measures suggest at least .1, more for small eta ... ok?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46883d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 'ego split', 1.0793527508090615, 7725, 0.684321], [1.0, 'beta 0.05', 2.520672740014015, 9989, 0.207882], [1.0, 'beta 0.075', 1.6116465863453815, 9960, 0.476698], [1.0, 'beta 0.1', 1.1803676025045446, 9902, 0.764883], [1.0, 'beta 0.125', 1.105140186915888, 9844, 0.83854], [1.0, 'beta 0.15', 1.041726324401718, 9778, 0.913737], [1.0, 'beta 0.175', 1.0169578622816033, 9730, 0.954529], [1.0, 'beta 0.2', 1.0050593701600412, 9685, 0.975585], [1.0, 'beta 0.225', 1.003113001971568, 9637, 0.972005], [1.0, 'beta 0.25', 1.0013635410111181, 9534, 0.96203]]\n",
      "[[1.0, 'ego split', 1.0793527508090615, 7725, 0.684321], [1.0, 'beta 0.05', 2.520672740014015, 9989, 0.207882], [1.0, 'beta 0.075', 1.6116465863453815, 9960, 0.476698], [1.0, 'beta 0.1', 1.1803676025045446, 9902, 0.764883], [1.0, 'beta 0.125', 1.105140186915888, 9844, 0.83854], [1.0, 'beta 0.15', 1.041726324401718, 9778, 0.913737], [1.0, 'beta 0.175', 1.0169578622816033, 9730, 0.954529], [1.0, 'beta 0.2', 1.0050593701600412, 9685, 0.975585], [1.0, 'beta 0.225', 1.003113001971568, 9637, 0.972005], [1.0, 'beta 0.25', 1.0013635410111181, 9534, 0.96203], [1.5, 'ego split', 1.1677492233832252, 7082, 0.381627], [1.5, 'beta 0.05', 4.016422992189065, 9986, 0.10956], [1.5, 'beta 0.075', 2.374092741935484, 9920, 0.254471], [1.5, 'beta 0.1', 1.4864809293718515, 9727, 0.546558], [1.5, 'beta 0.125', 1.3104502794474322, 9483, 0.535963], [1.5, 'beta 0.15', 1.1738512035010942, 9140, 0.524317], [1.5, 'beta 0.175', 1.0827242139459334, 8619, 0.492574], [1.5, 'beta 0.2', 1.0434413299356875, 8241, 0.47771], [1.5, 'beta 0.225', 1.0282442748091603, 7860, 0.450102], [1.5, 'beta 0.25', 1.0152537796976242, 7408, 0.429467]]\n",
      "[[1.0, 'ego split', 1.0793527508090615, 7725, 0.684321], [1.0, 'beta 0.05', 2.520672740014015, 9989, 0.207882], [1.0, 'beta 0.075', 1.6116465863453815, 9960, 0.476698], [1.0, 'beta 0.1', 1.1803676025045446, 9902, 0.764883], [1.0, 'beta 0.125', 1.105140186915888, 9844, 0.83854], [1.0, 'beta 0.15', 1.041726324401718, 9778, 0.913737], [1.0, 'beta 0.175', 1.0169578622816033, 9730, 0.954529], [1.0, 'beta 0.2', 1.0050593701600412, 9685, 0.975585], [1.0, 'beta 0.225', 1.003113001971568, 9637, 0.972005], [1.0, 'beta 0.25', 1.0013635410111181, 9534, 0.96203], [1.5, 'ego split', 1.1677492233832252, 7082, 0.381627], [1.5, 'beta 0.05', 4.016422992189065, 9986, 0.10956], [1.5, 'beta 0.075', 2.374092741935484, 9920, 0.254471], [1.5, 'beta 0.1', 1.4864809293718515, 9727, 0.546558], [1.5, 'beta 0.125', 1.3104502794474322, 9483, 0.535963], [1.5, 'beta 0.15', 1.1738512035010942, 9140, 0.524317], [1.5, 'beta 0.175', 1.0827242139459334, 8619, 0.492574], [1.5, 'beta 0.2', 1.0434413299356875, 8241, 0.47771], [1.5, 'beta 0.225', 1.0282442748091603, 7860, 0.450102], [1.5, 'beta 0.25', 1.0152537796976242, 7408, 0.429467], [2.0, 'ego split', 1.199159556857252, 7853, 0.298657], [2.0, 'beta 0.05', 4.8948843728100915, 9989, 0.0716921], [2.0, 'beta 0.075', 2.694539592988112, 9926, 0.20508], [2.0, 'beta 0.1', 1.5541871921182266, 9744, 0.378643], [2.0, 'beta 0.125', 1.350831054071113, 9506, 0.365332], [2.0, 'beta 0.15', 1.204962833406209, 9148, 0.348307], [2.0, 'beta 0.175', 1.0977202428685988, 8729, 0.336203], [2.0, 'beta 0.2', 1.0436858438768202, 8378, 0.328803], [2.0, 'beta 0.225', 1.0277743640162222, 8137, 0.322817], [2.0, 'beta 0.25', 1.0145631067961165, 7828, 0.309761]]\n",
      "[[1.0, 'ego split', 1.0793527508090615, 7725, 0.684321], [1.0, 'beta 0.05', 2.520672740014015, 9989, 0.207882], [1.0, 'beta 0.075', 1.6116465863453815, 9960, 0.476698], [1.0, 'beta 0.1', 1.1803676025045446, 9902, 0.764883], [1.0, 'beta 0.125', 1.105140186915888, 9844, 0.83854], [1.0, 'beta 0.15', 1.041726324401718, 9778, 0.913737], [1.0, 'beta 0.175', 1.0169578622816033, 9730, 0.954529], [1.0, 'beta 0.2', 1.0050593701600412, 9685, 0.975585], [1.0, 'beta 0.225', 1.003113001971568, 9637, 0.972005], [1.0, 'beta 0.25', 1.0013635410111181, 9534, 0.96203], [1.5, 'ego split', 1.1677492233832252, 7082, 0.381627], [1.5, 'beta 0.05', 4.016422992189065, 9986, 0.10956], [1.5, 'beta 0.075', 2.374092741935484, 9920, 0.254471], [1.5, 'beta 0.1', 1.4864809293718515, 9727, 0.546558], [1.5, 'beta 0.125', 1.3104502794474322, 9483, 0.535963], [1.5, 'beta 0.15', 1.1738512035010942, 9140, 0.524317], [1.5, 'beta 0.175', 1.0827242139459334, 8619, 0.492574], [1.5, 'beta 0.2', 1.0434413299356875, 8241, 0.47771], [1.5, 'beta 0.225', 1.0282442748091603, 7860, 0.450102], [1.5, 'beta 0.25', 1.0152537796976242, 7408, 0.429467], [2.0, 'ego split', 1.199159556857252, 7853, 0.298657], [2.0, 'beta 0.05', 4.8948843728100915, 9989, 0.0716921], [2.0, 'beta 0.075', 2.694539592988112, 9926, 0.20508], [2.0, 'beta 0.1', 1.5541871921182266, 9744, 0.378643], [2.0, 'beta 0.125', 1.350831054071113, 9506, 0.365332], [2.0, 'beta 0.15', 1.204962833406209, 9148, 0.348307], [2.0, 'beta 0.175', 1.0977202428685988, 8729, 0.336203], [2.0, 'beta 0.2', 1.0436858438768202, 8378, 0.328803], [2.0, 'beta 0.225', 1.0277743640162222, 8137, 0.322817], [2.0, 'beta 0.25', 1.0145631067961165, 7828, 0.309761], [2.5, 'ego split', 1.2109977949283353, 7256, 0.163182], [2.5, 'beta 0.05', 5.124499198717949, 9984, 0.064403], [2.5, 'beta 0.075', 2.7386478304742683, 9910, 0.146223], [2.5, 'beta 0.1', 1.5727943468772732, 9623, 0.251091], [2.5, 'beta 0.125', 1.3640289323113461, 9263, 0.234689], [2.5, 'beta 0.15', 1.2012398117322924, 8711, 0.224607], [2.5, 'beta 0.175', 1.0905730129390019, 8115, 0.20307], [2.5, 'beta 0.2', 1.0372361347843189, 7627, 0.207635], [2.5, 'beta 0.225', 1.025017088174983, 7315, 0.200966], [2.5, 'beta 0.25', 1.0132221902845646, 6958, 0.192358]]\n"
     ]
    }
   ],
   "source": [
    "Results = []\n",
    "min_size = 10\n",
    "THs = [.05,.075,.1,.125,.15,.175,.2,.225,.25]\n",
    "\n",
    "for eta in [1.0,1.5,2.0,2.5,3.0]:\n",
    "    G = readGraph(xi=0.35, eta=eta, rep=1)\n",
    "    G.vs['name'] = [str(i) for i in np.arange(G.vcount())]\n",
    "    #Counter([x for y in G.vs['comms'] for x in y]).most_common(5)\n",
    "    ## ground-truth communities without the outliers \n",
    "    GT = mems2comms(G.vs['comms'])[1:]  ## ignore \"outlier community\"\n",
    "    GT = [[str(i) for i in x] for x in GT]\n",
    "    #len(GT)\n",
    "    ## Ego-Split with 'CC' and 'ECG'\n",
    "    comms_es = EgoSplit(G, split='CC', algo='ECG')\n",
    "    ES = [list(x) for x in comms_es if len(x)>=min_size]    \n",
    "    ctr = Counter([i for j in ES for i in j])\n",
    "    Results.append([eta,'ego split',np.mean([x for x in ctr.values()]),len(ctr),compute_oNMI( ES, GT )])\n",
    "    C = sparse.csc_matrix((G.vcount(),len(ES)))\n",
    "    C.indices = np.array([int(i) for j in ES for i in j])\n",
    "    C.data = np.repeat(1,len(C.indices))\n",
    "    ptr = [0]\n",
    "    ctr = 0\n",
    "    for x in ES:\n",
    "        ctr += len(x)\n",
    "        ptr.append(ctr)\n",
    "    C.indptr = np.array(ptr)\n",
    "    M = C.tocsr()\n",
    "    ## Beta\n",
    "    IEF, Beta, C, Pv, DegPart = CAS(G.get_adjacency_sparse(), M)\n",
    "    for th in THs:\n",
    "        L = []\n",
    "        for i in range(Beta.shape[1]):\n",
    "            x = np.where( (np.array(Beta[:,i].todense()).flatten() >= th))[0]\n",
    "            if len(x)>0:\n",
    "                L.append(list(x))    \n",
    "        ctr = Counter([i for j in L for i in j])\n",
    "        Results.append([eta, 'beta '+str(th), np.mean([x for x in ctr.values()]),len(ctr),compute_oNMI(GT, L)])\n",
    "        #Results.append([rep, len(GT), len([i for j in GT for i in j])/G.vcount(), min_size, len(ES), th, compute_oNMI( ES, GT ), len([i for j in L for i in j])/G.vcount(), compute_oNMI(GT, L)])\n",
    "    print(Results)    \n",
    "df = pd.DataFrame(Results, columns=['eta','algorithm','avg_membership','outliers','onmi'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.algorithm\n",
    "y = []\n",
    "for s in x:\n",
    "    if s != 'ego split':\n",
    "        v = s.split(' ')\n",
    "        y.append('NIEF ('+v[1]+')')\n",
    "    else:\n",
    "        y.append(s)\n",
    "df['algorithm'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['outliers'] = 10000-df.outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c878d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x=\"eta\", y=\"onmi\", hue=\"algorithm\", data=df, palette='mako')\n",
    "plt.xlabel(r'$\\eta$', fontsize=14);\n",
    "plt.ylabel('oNMI', fontsize=14)\n",
    "plt.grid()\n",
    "plt.title('ABCD-oo graphs with varying $\\eta$', fontsize=16);\n",
    "plt.savefig('ego_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x=\"eta\", y=\"avg_membership\", hue=\"algorithm\", data=df, palette='mako');\n",
    "plt.xlabel(r'$\\eta$', fontsize=14);\n",
    "plt.ylabel('Average membership', fontsize=14)\n",
    "plt.grid()\n",
    "plt.title('ABCD-oo graphs with varying $\\eta$', fontsize=16);\n",
    "plt.savefig('ego_3.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8211a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x=\"eta\", y=\"outliers\", hue=\"algorithm\", data=df, palette='mako');\n",
    "plt.xlabel(r'$\\eta$', fontsize=14);\n",
    "plt.ylabel('Outliers', fontsize=14)\n",
    "plt.hlines(250,-0.5,4.5, color='grey', linestyle='dashed')\n",
    "plt.grid()\n",
    "plt.title('ABCD-oo graphs with varying $\\eta$', fontsize=16);\n",
    "plt.savefig('ego_2.png')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f8c1296",
   "metadata": {},
   "source": [
    "df_15 = pd.DataFrame(Results, columns=['rep','gt','gt_avg','min_size','es','th','es_onmi','beta_avg','beta_onmi'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba1bd284",
   "metadata": {},
   "source": [
    "with open('df_25.pkl','wb') as fp:\n",
    "    pickle.dump(df_25,fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a0496",
   "metadata": {},
   "source": [
    "## Computing oNMI over a range of threshold values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8814f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'Results/dfs_onmi.pkl'\n",
    "with open(fn,'rb') as fp:    \n",
    "    D, Leiden = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39bbe2d6",
   "metadata": {},
   "source": [
    "%%time\n",
    "TH = np.arange(10,331,10)/1000\n",
    "Lst = []\n",
    "rep = 1\n",
    "Ldn = []\n",
    "\n",
    "for eta in [1.0,1.5,2.0,2.5,3.0]:\n",
    "    for xi in [.35,.5,.65]:\n",
    "        for rep in [1,2,3,4,5,6,7,8,9,10]:\n",
    "            G = readGraph(xi, eta, rep) \n",
    "            GT = mem2comms(G.vs['comms'])[1:]  ## ignore \"outlier community\"\n",
    "            G.vs['leiden'] = G.community_leiden(objective_function='modularity').membership\n",
    "            Leiden = mem2comms([[j] for j in G.vs['leiden']])\n",
    "            ldn = compute_oNMI(GT, Leiden)\n",
    "            print(eta, xi, rep, 'Leiden:', ldn)\n",
    "            Ldn.append([eta,xi,ldn])\n",
    "            IEF, Beta, C, Pv, DegPart = CAS(G.get_adjacency_sparse(), partition2sparse(G.vs['leiden']))\n",
    "            for th1 in TH:\n",
    "                non_outliers = np.array((Beta >= th1).sum(axis=1)>0).flatten()\n",
    "                for th2 in TH:\n",
    "                    if th2 <= th1:\n",
    "                        L = []\n",
    "                        for i in range(Beta.shape[1]):\n",
    "                            x = np.where( (np.array(Beta[:,i].todense()).flatten() >= th2) & non_outliers)[0]\n",
    "                            if len(x)>0:\n",
    "                                L.append(list(x))\n",
    "                        Lst.append([eta, xi, th1, th2, G.vcount() - sum(non_outliers), compute_oNMI(GT,L), sum([len(x) for x in L]) / sum(non_outliers)])\n",
    "D = pd.DataFrame(Lst, columns=['eta', 'xi', 'th1', 'th2', 'outliers', 'oNMI','avg_membership'])\n",
    "Leiden = pd.DataFrame(Ldn, columns=['eta','xi','oNMI'])\n",
    "fn = 'dfs_onmi.pkl'\n",
    "with open(fn,'wb') as fp:\n",
    "    pickle.dump((D,Leiden),fp)\n",
    "D.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cef395",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "D['clustered'] = (10000 - D.outliers)/10000\n",
    "D['harmonic'] = 2/(1/D['oNMI'] + 1/D['clustered'])\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce8ee8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for xi in [.35,.5,.65]:\n",
    "    for eta in [1.0,1.5,2.0,2.5,3.0]:\n",
    "\n",
    "        df = D[ (D.xi==xi) & (D.eta==eta) ]\n",
    "        Dm = df.groupby(by=['eta','xi','th1','th2'], as_index=False).mean()\n",
    "\n",
    "\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(20, 8), gridspec_kw={'width_ratios': [.45, .1, .45]})\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        X = Dm.pivot_table(\n",
    "            index='th1',\n",
    "            columns='th2',\n",
    "            values='oNMI'\n",
    "        )\n",
    "        sns.heatmap(X, cmap='viridis')\n",
    "        plt.ylim(0,33)\n",
    "        plt.suptitle(r'$\\eta$ = '+str(eta)+r'  $\\xi$ ='+str(xi)+'  Leiden oNMI: '+str(Leiden[(Leiden.eta==eta) & (Leiden.xi==xi)].oNMI.iloc[0])[:6], fontsize=20)\n",
    "        plt.title('oNMI\\n'+'TOP:'+str(Dm.iloc[np.argmax(Dm.oNMI)]['oNMI'])[:6]+' outliers:'+str(int(np.round(Dm.iloc[np.argmax(Dm.oNMI)]['outliers']))), fontsize=14)\n",
    "        plt.ylabel('Outlier threshold', fontsize=14)\n",
    "        plt.xlabel('Community threshold', fontsize=14);\n",
    "\n",
    "        plt.subplot(1,3,2)\n",
    "        X = Dm.pivot_table(\n",
    "            index='th1',\n",
    "            columns='th2',\n",
    "            values='clustered'\n",
    "        )\n",
    "        sns.set(rc = {'figure.figsize':(8, 1)})\n",
    "        sns.heatmap(X, cmap='viridis', )\n",
    "        plt.ylim(0,33)\n",
    "        plt.xlim(.01,.02)\n",
    "        plt.title('Prop. clustered', fontsize=16)\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('')\n",
    "        plt.yticks([])\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        X = Dm.pivot_table(\n",
    "            index='th1',\n",
    "            columns='th2',\n",
    "            values='harmonic'\n",
    "        )\n",
    "        sns.heatmap(X, cmap='viridis')\n",
    "        plt.ylim(0,33)\n",
    "        plt.title('Harmonic mean\\n'+'TOP:'+str(Dm.iloc[np.argmax(Dm.harmonic)]['oNMI'])[:6]+' outliers:'+str(int(np.round(Dm.iloc[np.argmax(Dm.harmonic)]['outliers']))), fontsize=14)\n",
    "        plt.yticks([])\n",
    "        plt.xlabel('Community threshold', fontsize=14);\n",
    "        plt.ylabel('');\n",
    "\n",
    "        fn = 'abcdoo_thresholds_'+str(xi)+'_'+str(eta)+'.png'\n",
    "        plt.savefig(fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3f9712",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d9cbc7",
   "metadata": {},
   "source": [
    "## (1) AMI vs dropped nodes, ABCD-oo with eta == 1\n",
    "\n",
    "* (1a) use different scores to rank the nodes (w.r.t. outlyingness), but final score w.r.t. Leiden partition\n",
    "* (1b) actually use the scores for ranking AND scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4139a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Scores - only dropping 'outliers'\n",
    "XIs = [.35,.4,.45,.5,.55,.575,.6,.625,.65]\n",
    "REP = 1\n",
    "L = []\n",
    "for i in range(len(XIs)):\n",
    "    xi = XIs[i]\n",
    "    print(xi)\n",
    "    for rep in range(REP):\n",
    "        g = readGraph(xi=xi, eta=1.0, rep=rep+1)\n",
    "        num_nodes = g.vcount()\n",
    "        A = g.get_adjacency_sparse()\n",
    "        g.vs['leiden'] = g.community_leiden(objective_function='modularity').membership\n",
    "        g.vs['gt'] = [x[0] for x in g.vs['comms']]\n",
    "        ## Compute Beta, C; M is the community membership matrix w.r.t. C and c_star \n",
    "        IEF, Beta, C, P, DegPart = CAS(A, partition2sparse(g.vs['leiden']))\n",
    "        g.vs['IEF'] = IEF.max(axis=1).toarray().flatten()\n",
    "        g.vs['beta'] = Beta.max(axis=1).toarray().flatten()\n",
    "        g.vs['C'] = C.max(axis=1).toarray().flatten()\n",
    "        g.vs['P'] = P.max(axis=1).toarray().flatten()\n",
    "\n",
    "        ## rank w.r.t. top score, AMI w.r.t. original partition\n",
    "        r = np.argsort(g.vs['IEF'])\n",
    "        for k in range(num_nodes//4):\n",
    "            L.append([xi, 'IEF', k, AMI( np.array(g.vs['leiden'])[r[k:]] , np.array(g.vs['gt'])[r[k:]] )])        \n",
    "        r = np.argsort(g.vs['beta'])\n",
    "        for k in range(num_nodes//4):\n",
    "            L.append([xi, 'beta', k, AMI( np.array(g.vs['leiden'])[r[k:]] , np.array(g.vs['gt'])[r[k:]] )])        \n",
    "        r = np.argsort(g.vs['C'])\n",
    "        for k in range(num_nodes//4):\n",
    "            L.append([xi, 'C', k, AMI( np.array(g.vs['leiden'])[r[k:]] , np.array(g.vs['gt'])[r[k:]] )])        \n",
    "        r = np.argsort(g.vs['P'])\n",
    "        for k in range(num_nodes//4):\n",
    "            L.append([xi, 'P', k, AMI( np.array(g.vs['leiden'])[r[k:]] , np.array(g.vs['gt'])[r[k:]] )])        \n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "df = pd.DataFrame(L, columns=['xi','algo','dropped','ami']) \n",
    "for i in range(len(XIs)):\n",
    "    xi = XIs[i]\n",
    "    plt.subplot(3,3,i+1)\n",
    "    D = df[df.xi==XIs[i]]\n",
    "    D = D.groupby(by=['dropped','algo'])['ami'].mean()\n",
    "    plt.plot(D.loc[:,'IEF'].index, D.loc[:,'IEF'], label='IEF')\n",
    "    plt.plot(D.loc[:,'beta'].index, D.loc[:,'beta'], label='Beta')\n",
    "    plt.plot(D.loc[:,'C'].index, D.loc[:,'C'], label='C')\n",
    "    plt.plot(D.loc[:,'P'].index, D.loc[:,'P'], label='p-value')\n",
    "    if i==0:\n",
    "        plt.legend()\n",
    "    if i>5:\n",
    "        plt.xlabel('Dropped nodes')\n",
    "    if i%3==0:\n",
    "        plt.ylabel('AMI');\n",
    "    plt.title(r'$\\xi$ ='+str(xi))\n",
    "#plt.savefig('AMI_leiden.png');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7203fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Scores - using those\n",
    "L = []\n",
    "for i in range(len(XIs)):\n",
    "    xi = XIs[i]\n",
    "    print(xi)\n",
    "    for rep in range(REP):\n",
    "        g = readGraph(xi=xi, eta=1.0, rep=rep+1)\n",
    "        num_nodes = g.vcount()\n",
    "        A = g.get_adjacency_sparse()\n",
    "        g.vs['leiden'] = g.community_leiden(objective_function='modularity').membership\n",
    "        g.vs['gt'] = [x[0] for x in g.vs['comms']]\n",
    "        ## Compute Beta, C; M is the community membership matrix w.r.t. C and c_star \n",
    "        IEF, Beta, C, P, DegPart = CAS(A, partition2sparse(g.vs['leiden']))\n",
    "        g.vs['IEF'] = IEF.max(axis=1).toarray().flatten()\n",
    "        g.vs['IEF_top'] = np.array(IEF.argmax(axis=1)).flatten()\n",
    "        g.vs['beta'] = Beta.max(axis=1).toarray().flatten()\n",
    "        g.vs['beta_top'] = np.array(IEF.argmax(axis=1)).flatten()\n",
    "        g.vs['C'] = C.max(axis=1).toarray().flatten()\n",
    "        g.vs['C_top'] = np.array(IEF.argmax(axis=1)).flatten()\n",
    "        g.vs['P'] = P.max(axis=1).toarray().flatten()\n",
    "        g.vs['P_top'] = np.array(IEF.argmax(axis=1)).flatten()\n",
    "\n",
    "        ## rank w.r.t. top score, AMI w.r.t. original partition\n",
    "        r = np.argsort(g.vs['IEF'])\n",
    "        for k in range(num_nodes//4):\n",
    "            L.append([xi, 'IEF', k, AMI( np.array(g.vs['IEF_top'])[r[k:]] , np.array(g.vs['gt'])[r[k:]] )])        \n",
    "        r = np.argsort(g.vs['beta'])\n",
    "        for k in range(num_nodes//4):\n",
    "            L.append([xi, 'beta', k, AMI( np.array(g.vs['beta_top'])[r[k:]] , np.array(g.vs['gt'])[r[k:]] )])        \n",
    "        r = np.argsort(g.vs['C'])\n",
    "        for k in range(num_nodes//4):\n",
    "            L.append([xi, 'C', k, AMI( np.array(g.vs['C_top'])[r[k:]] , np.array(g.vs['gt'])[r[k:]] )])        \n",
    "        r = np.argsort(g.vs['P'])\n",
    "        for k in range(num_nodes//4):\n",
    "            L.append([xi, 'P', k, AMI( np.array(g.vs['P_top'])[r[k:]] , np.array(g.vs['gt'])[r[k:]] )])        \n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "df = pd.DataFrame(L, columns=['xi','algo','dropped','ami']) \n",
    "for i in range(len(XIs)):\n",
    "    xi = XIs[i]\n",
    "    plt.subplot(3,3,i+1)\n",
    "    D = df[df.xi==XIs[i]]\n",
    "    D = D.groupby(by=['dropped','algo'])['ami'].mean()\n",
    "    plt.plot(D.loc[:,'IEF'].index, D.loc[:,'IEF'], label='IEF')\n",
    "    plt.plot(D.loc[:,'beta'].index, D.loc[:,'beta'], label='Beta')\n",
    "    plt.plot(D.loc[:,'C'].index, D.loc[:,'C'], label='C')\n",
    "    plt.plot(D.loc[:,'P'].index, D.loc[:,'P'], label='p-value')\n",
    "    if i==0:\n",
    "        plt.legend()\n",
    "    if i>5:\n",
    "        plt.xlabel('Dropped nodes')\n",
    "    if i%3==0:\n",
    "        plt.ylabel('AMI');\n",
    "    plt.title(r'$\\xi$ ='+str(xi))\n",
    "#plt.savefig('AMI_scores.png');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1eb557",
   "metadata": {},
   "source": [
    "### (2) Classify outliers - ROC curves\n",
    "\n",
    "* now using larger eta value (choices: 1.0, 1.5, 2.0, 2.5, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f9b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec480d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f81cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f1873",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_out = 250\n",
    "ETA = 3.0\n",
    "XIs = [.6]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "\n",
    "for i in range(len(XIs)): \n",
    "    xi = XIs[i]\n",
    "    g = readGraph(xi=xi, eta=ETA, rep=1)\n",
    "    g.vs['gt'] = [x[0] for x in g.vs['comms']] ## pick the first; 0 == outlier\n",
    "    A = g.get_adjacency_sparse()\n",
    "    ## Leiden:\n",
    "    g.vs['leiden'] = g.community_leiden(objective_function='modularity').membership\n",
    "    IEF, Beta, C, P, DegPart = CAS(A, partition2sparse(g.vs['leiden']))\n",
    "    plt.subplot(3,3,i+1)\n",
    "\n",
    "    y = [int(x>0) for x in g.vs['gt']]\n",
    "\n",
    "    g.vs['IEF'] = IEF.max(axis=1).toarray().flatten()\n",
    "    fpr, tpr, thresholds = roc_curve(y, g.vs['IEF'], pos_label=1)\n",
    "    auc = AUC(y, g.vs['IEF'])\n",
    "    plt.plot(fpr, tpr, label='IEF: '+str(round(auc,3)))\n",
    "\n",
    "    g.vs['beta'] = Beta.max(axis=1).toarray().flatten()\n",
    "    fpr, tpr, thresholds = roc_curve(y, g.vs['beta'], pos_label=1)\n",
    "    auc = AUC(y, g.vs['beta'])\n",
    "    plt.plot(fpr, tpr, label='Beta: '+str(round(auc,3)))\n",
    "\n",
    "    g.vs['C'] = C.max(axis=1).toarray().flatten()\n",
    "    fpr, tpr, thresholds = roc_curve(y, g.vs['C'], pos_label=1)\n",
    "    auc = AUC(y, g.vs['C'])\n",
    "    plt.plot(fpr, tpr, label='C: '+str(round(auc,3)))\n",
    "\n",
    "    g.vs['P'] = P.max(axis=1).toarray().flatten()\n",
    "    fpr, tpr, thresholds = roc_curve(y, g.vs['P'], pos_label=1)\n",
    "    auc = AUC(y, g.vs['P'])\n",
    "    plt.plot(fpr, tpr, label='p-value: '+str(round(auc,3)))\n",
    "\n",
    "    plt.legend(title='AUC')\n",
    "    if i>5:\n",
    "        plt.xlabel('FPR')\n",
    "    if i%3==0:\n",
    "        plt.ylabel('TPR');\n",
    "    plt.legend()\n",
    "    plt.title(r'ROC for $\\xi$ ='+str(xi))  \n",
    "#plt.savefig('abcdoo_ROC_scores_eta_3_0.png')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7179ac47",
   "metadata": {},
   "source": [
    "### (3) Scores, varying threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0dcc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETA = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f946c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "range_IEF = np.arange(.05,.501,.025)\n",
    "range_beta = np.arange(.05,.501,.025)\n",
    "range_C = np.arange(1,8.001,.25)\n",
    "range_P = np.arange(.90,1,.0025)\n",
    "\n",
    "L = []\n",
    "for xi in XIs:\n",
    "    g = readGraph(xi=xi, eta=ETA, rep=1)\n",
    "    g.vs['leiden'] = g.community_leiden(objective_function='modularity').membership\n",
    "    g.vs['gt'] = [x[0] for x in g.vs['comms']] ## pick the first; 0 == outlier\n",
    "    A = g.get_adjacency_sparse()\n",
    "    IEF, Beta, C, P, DegPart = CAS(A, partition2sparse(g.vs['leiden']))\n",
    "#     for th in range_IEF:\n",
    "#         M = score_to_memberships(IEF, DegPart, th)\n",
    "#         L.append(['IEF', xi, th, Counter(np.array(M.sum(axis=1)).flatten())[0], sum((np.array(M.sum(axis=1)).flatten() == 0) & (np.array(g.vs['gt']) == 0))])\n",
    "    for th in range_beta:\n",
    "        M = score_to_memberships(Beta, DegPart, th)\n",
    "        L.append(['Beta', xi, th, Counter(np.array(M.sum(axis=1)).flatten())[0], sum((np.array(M.sum(axis=1)).flatten() == 0) & (np.array(g.vs['gt']) == 0))])\n",
    "#     for th in range_C:\n",
    "#         M = score_to_memberships(C, DegPart, th)\n",
    "#         L.append(['C', xi, th, Counter(np.array(M.sum(axis=1)).flatten())[0], sum((np.array(M.sum(axis=1)).flatten() == 0) & (np.array(g.vs['gt']) == 0))])\n",
    "#     for th in range_P:\n",
    "#         M = score_to_memberships(P, DegPart, th)\n",
    "#         L.append(['P', xi, th, Counter(np.array(M.sum(axis=1)).flatten())[0], sum((np.array(M.sum(axis=1)).flatten() == 0) & (np.array(g.vs['gt']) == 0))])\n",
    "\n",
    "df = pd.DataFrame(L, columns=['score','xi','threshold','outliers','TP'])\n",
    "df['FP'] = df['outliers'] - df['TP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42af92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df[df.score == 'Beta']\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "\n",
    "for i in range(len(XIs)):\n",
    "    xi = XIs[i]\n",
    "    D = _df[_df.xi == xi]\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.plot(D.threshold, D.TP, label='True Positives')\n",
    "    plt.plot(D.threshold, D.FP, label='False Positives')\n",
    "    plt.hlines(y=num_out, xmin=min(D.threshold), xmax=max(D.threshold), linestyles='dotted', color='grey')\n",
    "    plt.ylim((-10,1000))\n",
    "    if i==0:\n",
    "        plt.legend()\n",
    "    if i>5:\n",
    "        plt.xlabel('threshold')\n",
    "    if i%3==0:\n",
    "        plt.ylabel('Count');\n",
    "    plt.title(r'Outliers with $\\xi$ ='+str(xi)) \n",
    "#plt.savefig('abcdoo_TP_FP_Beta_eta_3_0.png');    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d583199",
   "metadata": {},
   "source": [
    "## More tests - as with DBLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f081f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "XI = 0.35\n",
    "ETA = 1.5\n",
    "REP = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a5faa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = readGraph(xi=XI, eta=ETA, rep=REP)\n",
    "G.vs['leiden'] = G.community_leiden(objective_function='modularity').membership\n",
    "G.vs['gt'] = [x[0] for x in G.vs['comms']] ## pick the first; 0 == outlier\n",
    "## Add community degrees to G (deg_A(v)'s)\n",
    "for v in G.vs:\n",
    "    ctr = Counter([i for x in v.neighbors() for i in x['comms']])\n",
    "    v['degrees'] = [ctr[i] if i in ctr.keys() else 0 for i in v['comms'] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0634cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = G.get_adjacency_sparse()\n",
    "IEF, Beta, C, Pv, DegPart = CAS(A, partition2sparse(G.vs['leiden']), alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Thresholds below are somewhat arbitrary\n",
    "\n",
    "M = score_to_memberships(IEF, DegPart, threshold=.25)\n",
    "outliers = np.where(np.array(M.sum(axis=1).flatten().tolist()[0])==0)[0]\n",
    "print('IEF:')\n",
    "print('outliers found:',len(outliers))\n",
    "print('ground-truth outliers found:',sum([G.vs[i]['gt']==0 for i in outliers]))\n",
    "\n",
    "M = score_to_memberships(Beta, DegPart, threshold=.25)\n",
    "outliers = np.where(np.array(M.sum(axis=1).flatten().tolist()[0])==0)[0]\n",
    "print('\\nBeta score:')\n",
    "print('outliers found:',len(outliers))\n",
    "print('ground-truth outliers found:',sum([G.vs[i]['gt']==0 for i in outliers]))\n",
    "\n",
    "M = score_to_memberships(C, DegPart, threshold=3)\n",
    "outliers = np.where(np.array(M.sum(axis=1).flatten().tolist()[0])==0)[0]\n",
    "print('\\nC score:')\n",
    "print('outliers found:',len(outliers))\n",
    "print('ground-truth outliers found:',sum([G.vs[i]['gt']==0 for i in outliers]))\n",
    "\n",
    "M = score_to_memberships(Pv, DegPart, threshold=.95)\n",
    "outliers = np.where(np.array(M.sum(axis=1).flatten().tolist()[0])==0)[0]\n",
    "print('\\np-value score:')\n",
    "print('outliers found:',len(outliers))\n",
    "print('ground-truth outliers found:',sum([G.vs[i]['gt']==0 for i in outliers]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b23de6d",
   "metadata": {},
   "source": [
    "# Experiment with overlapping ground-truth (gt) communities\n",
    "\n",
    "* Input: membership (sparse) matrix M and (Sparse) adjacency A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125e7d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "plt.style.use('default')\n",
    "K = 3\n",
    "for xi in [0.4,0.65]:\n",
    "    for eta in [1.5,3.0]:\n",
    "        G = readGraph(xi=xi, eta=eta, rep=1)\n",
    "        G.vs['leiden'] = G.community_leiden(objective_function='modularity').membership\n",
    "        G.vs['gt'] = [x[0] for x in G.vs['comms']] ## pick the first; 0 == outlier\n",
    "\n",
    "        ## Add community degrees to G (deg_A(v)'s)\n",
    "        for v in G.vs:\n",
    "            ctr = Counter([i for x in v.neighbors() for i in x['comms']])\n",
    "            v['degrees'] = [ctr[i] if i in ctr.keys() else 0 for i in v['comms'] ]\n",
    "\n",
    "        ## GT community membership matrix\n",
    "        X = np.repeat(np.arange(G.vcount(), dtype=int), G.vs['n_comms'])\n",
    "        Y = np.array([i for j in G.vs['comms'] for i in j])\n",
    "        n = len(X)\n",
    "        M = sparse.csr_matrix( (np.repeat(1,n), (X,Y)), shape=(G.vcount(), max(Y)+1) )\n",
    "        A = G.get_adjacency_sparse()\n",
    "\n",
    "        ## Compute CAS measures\n",
    "        IEF, Beta, C, Pv, DegPart = CAS(A, M, alpha=1)\n",
    "        \n",
    "        ## compute average \n",
    "        V = np.array(G.vs['n_comms']) == K\n",
    "        GT = np.array([G.vs[v]['comms'] for v in np.where(V)])[0] \n",
    "        Degs = np.array([G.vs[v]['degrees'] for v in np.where(V)])[0]        \n",
    "\n",
    "        plt.figure(figsize=(12,10))\n",
    "        ## IEF\n",
    "        X = IEF[V]\n",
    "        L = []\n",
    "        for i in range(GT.shape[0]):\n",
    "            x = np.argsort(X[i].toarray()[0])[::-1]\n",
    "            L.append([np.where(x==GT[i][j])[0][0] for j in range(K) ])\n",
    "        df = pd.DataFrame(np.array(L)+1)\n",
    "        my_dict = {}\n",
    "        for j in [1,2,3,4,5,6,7,8]:\n",
    "            _df = df[np.min(Degs, axis=1) >= j]\n",
    "            x = _df.mean(axis=1)\n",
    "            my_dict[str(j)] = list(x)\n",
    "        plt.subplot(221)\n",
    "        plt.hlines((K+1)/2,0,7,linestyles='dotted')\n",
    "        ax = sns.boxplot([x for x in my_dict.values()], showfliers=False, );\n",
    "        ax.set_xticks(np.arange(8))\n",
    "        ax.grid(linestyle=':')\n",
    "        ax.set_xticklabels(my_dict.keys())\n",
    "        plt.ylabel('average rank for '+str(K)+' communities', fontsize=12);\n",
    "        plt.title('IEF', fontsize=14);\n",
    "\n",
    "        ## Beta\n",
    "        X = Beta[V]\n",
    "        L = []\n",
    "        for i in range(GT.shape[0]):\n",
    "            x = np.argsort(X[i].toarray()[0])[::-1]\n",
    "            L.append([np.where(x==GT[i][j])[0][0] for j in range(K) ])\n",
    "        df = pd.DataFrame(np.array(L)+1)\n",
    "        my_dict = {}\n",
    "        for j in [1,2,3,4,5,6,7,8]:\n",
    "            _df = df[np.min(Degs, axis=1) >= j]\n",
    "            x = _df.mean(axis=1)\n",
    "            my_dict[str(j)] = list(x)\n",
    "        plt.subplot(222)\n",
    "        plt.hlines((K+1)/2,0,7,linestyles='dotted')\n",
    "        ax = sns.boxplot([x for x in my_dict.values()], showfliers=False, );\n",
    "        ax.set_xticks(np.arange(8))\n",
    "        ax.grid(linestyle=':')\n",
    "        ax.set_xticklabels(my_dict.keys())\n",
    "        #plt.xlabel('min community degree at least');\n",
    "        #plt.ylabel('average rank for '+str(K)+' communities');\n",
    "        plt.title('Beta', fontsize=14);\n",
    "\n",
    "        ## C\n",
    "        X = C[V]\n",
    "        L = []\n",
    "        for i in range(GT.shape[0]):\n",
    "            x = np.argsort(X[i].toarray()[0])[::-1]\n",
    "            L.append([np.where(x==GT[i][j])[0][0] for j in range(K) ])\n",
    "        df = pd.DataFrame(np.array(L)+1)\n",
    "        my_dict = {}\n",
    "        for j in [1,2,3,4,5,6,7,8]:\n",
    "            _df = df[np.min(Degs, axis=1) >= j]\n",
    "            x = _df.mean(axis=1)\n",
    "            my_dict[str(j)] = list(x)\n",
    "        plt.subplot(223)\n",
    "        plt.hlines((K+1)/2,0,7,linestyles='dotted')\n",
    "        ax = sns.boxplot([x for x in my_dict.values()], showfliers=False, );\n",
    "        ax.set_xticks(np.arange(8))\n",
    "        ax.grid(linestyle=':')\n",
    "        ax.set_xticklabels(my_dict.keys())\n",
    "        plt.xlabel('Minimum in-community degree', fontsize=12);\n",
    "        plt.ylabel('average rank for '+str(K)+' communities', fontsize=12);\n",
    "        plt.title('C', fontsize=14);\n",
    "\n",
    "        ## Pv\n",
    "        X = Pv[V]\n",
    "        L = []\n",
    "        for i in range(GT.shape[0]):\n",
    "            x = np.argsort(X[i].toarray()[0])[::-1]\n",
    "            L.append([np.where(x==GT[i][j])[0][0] for j in range(K) ])\n",
    "        df = pd.DataFrame(np.array(L)+1)\n",
    "        my_dict = {}\n",
    "        for j in [1,2,3,4,5,6,7,8]:\n",
    "            _df = df[np.min(Degs, axis=1) >= j]\n",
    "            x = _df.mean(axis=1)\n",
    "            my_dict[str(j)] = list(x)\n",
    "        plt.subplot(224)\n",
    "        plt.hlines((K+1)/2,0,7,linestyles='dotted')\n",
    "        ax = sns.boxplot([x for x in my_dict.values()], showfliers=False, );\n",
    "        ax.set_xticks(np.arange(8))\n",
    "        ax.grid(linestyle=':')\n",
    "        ax.set_xticklabels(my_dict.keys())\n",
    "        plt.xlabel('Minimum in-community degree', fontsize=12);\n",
    "        #plt.ylabel('average rank for '+str(K)+' communities');\n",
    "        plt.title('p-values', fontsize=14);\n",
    "\n",
    "        ## save PNG\n",
    "        fn = 'abcdoo_'+str(xi)+'_'+str(eta)+'_'+str(K)+'.png'\n",
    "        plt.savefig(fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc180fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = readGraph(xi=0.5, eta=1.5, rep=1)\n",
    "G.vs['leiden'] = G.community_leiden(objective_function='modularity').membership\n",
    "G.vs['gt'] = [x[0] for x in G.vs['comms']] ## pick the first; 0 == outlier\n",
    "## Add community degrees to G (deg_A(v)'s)\n",
    "for v in G.vs:\n",
    "    ctr = Counter([i for x in v.neighbors() for i in x['comms']])\n",
    "    v['degrees'] = [ctr[i] if i in ctr.keys() else 0 for i in v['comms'] ]\n",
    "\n",
    "MAX = 8\n",
    "MINDEG = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c83f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NumIEF = np.zeros(MAX)\n",
    "NumBeta = np.zeros(MAX)\n",
    "NumC = np.zeros(MAX)\n",
    "NumPv = np.zeros(MAX)\n",
    "Den = np.zeros(MAX)\n",
    "\n",
    "for K in (np.arange(MAX)+1):\n",
    "    V = np.array(G.vs['n_comms'])>=K\n",
    "    minDeg = np.array([min(v['degrees']) if v['n_comms']>0 else 0 for v in G.vs]) >= MINDEG\n",
    "    V = V & minDeg\n",
    "    Si = Sb = Sc = Sp = 0\n",
    "    for i in range(len(V)):\n",
    "        if V[i]:\n",
    "            x = np.argsort(IEF[i].toarray()[0])[-K]\n",
    "            Si += ((x) in G.vs[i]['comms'])\n",
    "            x = np.argsort(Beta[i].toarray()[0])[-K]\n",
    "            Sb += ((x) in G.vs[i]['comms'])\n",
    "            x = np.argsort(C[i].toarray()[0])[-K]\n",
    "            Sc += ((x) in G.vs[i]['comms'])\n",
    "            x = np.argsort(Pv[i].toarray()[0])[-K]\n",
    "            Sp += ((x) in G.vs[i]['comms'])\n",
    "            \n",
    "    NumBeta[K-1] = Sb\n",
    "    NumC[K-1] = Sc\n",
    "    NumIEF[K-1] = Si\n",
    "    NumPv[K-1] = Sp\n",
    "    Den[K-1] = sum(V)\n",
    "\n",
    "plt.plot(np.arange(MAX)+1, NumIEF/Den, '.-', label='IEF')\n",
    "plt.plot(np.arange(MAX)+1, NumBeta/Den, '.-', label='Beta')\n",
    "plt.plot(np.arange(MAX)+1, NumC/Den, '.-', label='C')\n",
    "plt.plot(np.arange(MAX)+1, NumPv/Den, '.-', label='p-values')\n",
    "plt.xlabel('K (considering nodes with at least K ground-truth communities)')\n",
    "plt.ylabel('P(Kth highest scoring is a true community)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('ABCD-oo ');\n",
    "fn = 'abcdoo_ranked_0.5_3.0.png'\n",
    "#plt.savefig(fn);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "gt = []\n",
    "nc = []\n",
    "for ctr in np.arange(1,MAX+1):\n",
    "    V = np.array(G.vs['n_comms']) == ctr\n",
    "    for i in range(len(V)):\n",
    "        if V[i]:\n",
    "            x = IEF[i].toarray()[0]\n",
    "            y = np.array(G.vs[i]['comms'])\n",
    "            score.extend([x[i] for i in y])\n",
    "            gt.extend(np.repeat(True,len(y)))\n",
    "            score.extend(x[x>0])\n",
    "            gt.extend(np.repeat(False,sum(x>0)))\n",
    "            nc.extend(np.repeat(ctr,len(y)+sum(x>0)))\n",
    "D = pd.DataFrame( np.array([score,gt,nc]).transpose(), columns=['IEF','gt','number of communities'])\n",
    "D['number of communities'] = [int(x) for x in D['number of communities']]\n",
    "g = sns.boxplot(x='number of communities', y='IEF', hue='gt', data=D, \n",
    "                showfliers=False, legend='full')\n",
    "leg = g.axes.get_legend()\n",
    "leg.set_title('IEF scores')\n",
    "new_labels = ['all non-zero','ground-truth only']\n",
    "for t, l in zip(leg.texts, new_labels):\n",
    "    t.set_text(l)\n",
    "fn = 'abcdoo_ied_0.5_3.0.png'\n",
    "plt.savefig(fn);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d41697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "gt = []\n",
    "nc = []\n",
    "for ctr in np.arange(1,MAX+1):\n",
    "    V = np.array(G.vs['n_comms']) == ctr\n",
    "    for i in range(len(V)):\n",
    "        if V[i]:\n",
    "            x = Beta[i].toarray()[0]\n",
    "            y = np.array(G.vs[i]['comms'])\n",
    "            score.extend([x[i] for i in y])\n",
    "            gt.extend(np.repeat(True,len(y)))\n",
    "            score.extend(x[x>0])\n",
    "            gt.extend(np.repeat(False,sum(x>0)))\n",
    "            nc.extend(np.repeat(ctr,len(y)+sum(x>0)))\n",
    "D = pd.DataFrame( np.array([score,gt,nc]).transpose(), columns=['Beta','gt','number of communities'])\n",
    "D['number of communities'] = [int(x) for x in D['number of communities']]\n",
    "g = sns.boxplot(x='number of communities', y='Beta', hue='gt', data=D, \n",
    "                showfliers=False, legend='full')\n",
    "leg = g.axes.get_legend()\n",
    "leg.set_title('Beta scores')\n",
    "new_labels = ['all non-zero','ground-truth only']\n",
    "for t, l in zip(leg.texts, new_labels):\n",
    "    t.set_text(l)\n",
    "fn = 'abcdoo_beta_0.5_3.0.png'\n",
    "plt.savefig(fn);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "gt = []\n",
    "nc = []\n",
    "for ctr in np.arange(1,MAX+1):\n",
    "    V = np.array(G.vs['n_comms']) == ctr\n",
    "    for i in range(len(V)):\n",
    "        if V[i]:\n",
    "            x = C[i].toarray()[0]\n",
    "            y = np.array(G.vs[i]['comms'])\n",
    "            score.extend([x[i] for i in y])\n",
    "            gt.extend(np.repeat(True,len(y)))\n",
    "            score.extend(x[x>0])\n",
    "            gt.extend(np.repeat(False,sum(x>0)))\n",
    "            nc.extend(np.repeat(ctr,len(y)+sum(x>0)))\n",
    "D = pd.DataFrame( np.array([score,gt,nc]).transpose(), columns=['C','gt','number of communities'])\n",
    "D['number of communities'] = [int(x) for x in D['number of communities']]\n",
    "g = sns.boxplot(x='number of communities', y='C', hue='gt', data=D, \n",
    "                showfliers=False, legend='full')\n",
    "leg = g.axes.get_legend()\n",
    "leg.set_title('C scores')\n",
    "new_labels = ['all non-zero','ground-truth only']\n",
    "for t, l in zip(leg.texts, new_labels):\n",
    "    t.set_text(l)\n",
    "fn = 'abcdoo_c_0.5_3.0.png'\n",
    "plt.savefig(fn);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176e28a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "gt = []\n",
    "nc = []\n",
    "for ctr in np.arange(1,MAX+1):\n",
    "    V = np.array(G.vs['n_comms']) == ctr\n",
    "    for i in range(len(V)):\n",
    "        if V[i]:\n",
    "            x = Pv[i].toarray()[0]\n",
    "            y = np.array(G.vs[i]['comms'])\n",
    "            score.extend([x[i] for i in y])\n",
    "            gt.extend(np.repeat(True,len(y)))\n",
    "            score.extend(x[x>0])\n",
    "            gt.extend(np.repeat(False,sum(x>0)))\n",
    "            nc.extend(np.repeat(ctr,len(y)+sum(x>0)))\n",
    "D = pd.DataFrame( np.array([score,gt,nc]).transpose(), columns=['P','gt','number of communities'])\n",
    "D['number of communities'] = [int(x) for x in D['number of communities']]\n",
    "g = sns.boxplot(x='number of communities', y='P', hue='gt', data=D, \n",
    "                showfliers=False, legend='full')\n",
    "leg = g.axes.get_legend()\n",
    "leg.set_title('P scores')\n",
    "new_labels = ['all non-zero','ground-truth only']\n",
    "for t, l in zip(leg.texts, new_labels):\n",
    "    t.set_text(l)\n",
    "plt.ylim(.5,1);\n",
    "fn = 'abcdoo_p_0.5_3.0.png'\n",
    "plt.savefig(fn);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f06dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(G.vs['n_comms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af323cd",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0e8a4",
   "metadata": {},
   "source": [
    "## Testing Rising Tide Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae1d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = readGraph(xi=0.4, eta=1.5, rep=1)\n",
    "A = G.get_adjacency_sparse()\n",
    "M = partition2sparse(G.community_leiden(objective_function='modularity').membership)\n",
    "IEF, Beta, C, Pv, DegPart = CAS(A,M)\n",
    "Counter(np.array(M.sum(axis=1)).flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = score_to_memberships(Beta, DegPart, threshold=.2, min_deg_in=2)\n",
    "Counter(np.array(B.sum(axis=1)).flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4680c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(G.vs['n_comms'] == np.array(B.sum(axis=1)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f255d80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RT = rising_tide(A, Beta, min_deg_in=2)\n",
    "Counter(np.array(RT.sum(axis=1)).flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb110e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(G.vs['n_comms'] == np.array(RT.sum(axis=1)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987cdcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Counter(np.array(RT.sum(axis=1)).flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c179bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.vs['gt'] = [x[0] for x in G.vs['comms']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe4539",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMI(G.vs['gt'], G.community_leiden(objective_function='modularity').membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dbd3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMI(G.vs['gt'], np.array(Beta.argmax(axis=1)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMI(G.vs['gt'], np.array(RT.argmax(axis=1)).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f6cba",
   "metadata": {},
   "source": [
    "## Testing edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = readGraph(xi=0.4, eta=1.5, rep=1)\n",
    "## GT community membership matrix\n",
    "X = np.repeat(np.arange(G.vcount(), dtype=int), G.vs['n_comms'])\n",
    "Y = np.array([i for j in G.vs['comms'] for i in j])\n",
    "n = len(X)\n",
    "M = sparse.csr_matrix( (np.repeat(1,n), (X,Y)), shape=(G.vcount(), max(Y)+1) )\n",
    "A = G.get_adjacency_sparse()\n",
    "\n",
    "## Compute CAS measures\n",
    "IEF, Beta, C, Pv, DegPart = CAS(A, M, alpha=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f151c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add community degrees to G (deg_A(v)'s)\n",
    "for v in G.vs:\n",
    "    ctr = Counter([i for x in v.neighbors() for i in x['comms']])\n",
    "    v['degrees'] = [ctr[i] if i in ctr.keys() else 0 for i in v['comms'] ]\n",
    "## set outliers to 0\n",
    "b = np.where(np.array([x[0]==0 for x in G.vs['comms']]))[0]\n",
    "for i in b:\n",
    "    G.vs[i]['n_comms'] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd2859",
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = []\n",
    "Inter = []\n",
    "for e in G.es:\n",
    "    Score.append(np.max(np.minimum(np.array(Beta[e.source].todense())[0], np.array(Beta[e.target].todense())[0])))\n",
    "    Inter.append(len(set(G.vs[e.source]['comms']).intersection(set(G.vs[e.target]['comms']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Score'] = Score\n",
    "df['Intersection'] = Inter\n",
    "sns.boxplot(y='Score', x='Intersection', data=df)\n",
    "plt.grid();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c8c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Leiden\n",
    "M = partition2sparse(G.community_leiden(objective_function='modularity').membership)\n",
    "IEF, Beta, C, Pv, DegPart = CAS(A,M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f2f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = []\n",
    "Inter = []\n",
    "for e in G.es:\n",
    "    Score.append(np.max(np.minimum(np.array(Beta[e.source].todense())[0], np.array(Beta[e.target].todense())[0])))\n",
    "    Inter.append(len(set(G.vs[e.source]['comms']).intersection(set(G.vs[e.target]['comms']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788dea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Score'] = Score\n",
    "df['Intersection'] = Inter\n",
    "sns.boxplot(y='Score', x='Intersection', data=df)\n",
    "plt.grid();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676fab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop edges\n",
    "E = np.where(np.array(Score)<.1)[0]\n",
    "G.delete_edges(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d25bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.vs['gt'] = [x[0] for x in G.vs['comms']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91895526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AMI(G.vs['gt'], G.community_leiden(objective_function='modularity').membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5dc9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(G.vs['n_comms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(Inter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "complexnetworks",
   "language": "python",
   "name": "complexnetworks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
